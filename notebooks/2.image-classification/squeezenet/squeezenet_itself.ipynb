{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Summary of SqueezeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeezenet_summary(net, layer_type=False, layer_shape=False, \n",
    "                       get_flops=False, get_memory=False,\n",
    "                       get_total_time=False, get_layer_time=False):\n",
    "    # check if the model is empty\n",
    "    if net.empty():\n",
    "        print(\"Net is empty\")\n",
    "        return\n",
    "        \n",
    "    # get the types of layers used in the model\n",
    "    if layer_type:\n",
    "        print(\"\\nNet contains:\")\n",
    "        for t in net.getLayerTypes():\n",
    "            print(\"\\t{} layers of type {}\".format(net.getLayersCount(t), t))\n",
    "        \n",
    "    \n",
    "    \n",
    "    # get the tensor shapes for the loaded model and specified input shape\n",
    "    if layer_shape:\n",
    "        layers_ids, in_shapes, out_shapes = net.getLayersShapes([1, 3, 224, 224])\n",
    "        layers_names = net.getLayerNames()\n",
    "        print(\"\\nNet layers shapes: \")\n",
    "        for l in range(len(layers_names)):\n",
    "            in_num, out_num = len(in_shapes[l]), len(out_shapes[l])\n",
    "            print(\"  Layer {} has {} inputs and {} outputs\".format(layers_names[l],\n",
    "                                                                 in_num, out_num))\n",
    "            for i in range(in_num):\n",
    "                print(\"\\tinput #{} has shape {}\".format(i, in_shapes[l][i].flatten()))\n",
    "            for i in range(out_num):\n",
    "                print(\"\\toutput #{} has shape {}\".format(i, out_shapes[l][i].flatten()))\n",
    "            \n",
    "    # compute the number of FLOPs\n",
    "    if get_flops:\n",
    "        print(\"\\ngflops: \", net.getFLOPS((1, 3, 224, 224)) * 1e-9)\n",
    "    \n",
    "    # report the amount of memory consumed for storing weights and intermediate tensors\n",
    "    if get_memory:\n",
    "        w, b = net.getMemoryConsumption((1, 3, 224, 224))\n",
    "        print(\"\\nweights (mb):\", w * 1e-6, \", blobs (mb):\", b * 1e-6)\n",
    "    \n",
    "    # perform a forward pass for a mock input\n",
    "    blob = cv2.dnn.blobFromImage(np.zeros((224, 224, 3), np.uint8), 1, (224, 224))\n",
    "    net.setInput(blob)\n",
    "    net.forward()\n",
    "    \n",
    "    # report the total time\n",
    "    if get_total_time:\n",
    "        total, timings = net.getPerfProfile()\n",
    "        tick2ms = 1000 / cv2.getTickFrequency()\n",
    "        print(\"\\ninference (ms): {:2f}\".format(total * tick2ms))\n",
    "    \n",
    "    # report the per layer inference time\n",
    "    if get_layer_time:\n",
    "        layer_names = net.getLayerNames()\n",
    "        print(\"\\n{: <30} {}\".format(\"LAYER\", \"TIME (ms)\"))\n",
    "        for (i,t) in enumerate(timings):\n",
    "            print(\"{: <30} {:.2f}\".format(layer_names[i], t[0] * tick2ms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the model\n",
    "model_path = \"./model/squeezenet_v1.1.caffemodel\"\n",
    "proto_path = \"./model/squeezenet_v1.1.prototxt\"\n",
    "squeezenet = cv2.dnn.readNetFromCaffe(proto_path, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Net contains:\n",
      "\t8 layers of type Concat\n",
      "\t26 layers of type Convolution\n",
      "\t1 layers of type Dropout\n",
      "\t1 layers of type Flatten\n",
      "\t4 layers of type Pooling\n",
      "\t26 layers of type ReLU\n",
      "\t1 layers of type Softmax\n",
      "\t1 layers of type __NetInputLayer__\n"
     ]
    }
   ],
   "source": [
    "squeezenet_summary(squeezenet, layer_type=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Net layers shapes: \n",
      "  Layer conv1 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [  1   3 224 224]\n",
      "\toutput #0 has shape [  1   3 224 224]\n",
      "  Layer relu_conv1 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [  1   3 224 224]\n",
      "\toutput #0 has shape [  1  64 111 111]\n",
      "  Layer pool1 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [  1  64 111 111]\n",
      "\toutput #0 has shape [  1  64 111 111]\n",
      "  Layer fire2/squeeze1x1 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [  1  64 111 111]\n",
      "\toutput #0 has shape [ 1 64 55 55]\n",
      "  Layer fire2/relu_squeeze1x1 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [ 1 64 55 55]\n",
      "\toutput #0 has shape [ 1 16 55 55]\n",
      "  Layer fire2/expand1x1 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [ 1 16 55 55]\n",
      "\toutput #0 has shape [ 1 16 55 55]\n",
      "  Layer fire2/relu_expand1x1 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [ 1 16 55 55]\n",
      "\toutput #0 has shape [ 1 64 55 55]\n",
      "  Layer fire2/expand3x3 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [ 1 64 55 55]\n",
      "\toutput #0 has shape [ 1 64 55 55]\n",
      "  Layer fire2/relu_expand3x3 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [ 1 16 55 55]\n",
      "\toutput #0 has shape [ 1 64 55 55]\n",
      "  Layer fire2/concat has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [ 1 64 55 55]\n",
      "\toutput #0 has shape [ 1 64 55 55]\n",
      "  Layer fire3/squeeze1x1 has 2 inputs and 1 outputs\n",
      "\tinput #0 has shape [ 1 64 55 55]\n",
      "\tinput #1 has shape [ 1 64 55 55]\n",
      "\toutput #0 has shape [  1 128  55  55]\n",
      "  Layer fire3/relu_squeeze1x1 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [  1 128  55  55]\n",
      "\toutput #0 has shape [ 1 16 55 55]\n",
      "  Layer fire3/expand1x1 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [ 1 16 55 55]\n",
      "\toutput #0 has shape [ 1 16 55 55]\n",
      "  Layer fire3/relu_expand1x1 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [ 1 16 55 55]\n",
      "\toutput #0 has shape [ 1 64 55 55]\n",
      "  Layer fire3/expand3x3 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [ 1 64 55 55]\n",
      "\toutput #0 has shape [ 1 64 55 55]\n",
      "  Layer fire3/relu_expand3x3 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [ 1 16 55 55]\n",
      "\toutput #0 has shape [ 1 64 55 55]\n",
      "  Layer fire3/concat has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [ 1 64 55 55]\n",
      "\toutput #0 has shape [ 1 64 55 55]\n",
      "  Layer pool3 has 2 inputs and 1 outputs\n",
      "\tinput #0 has shape [ 1 64 55 55]\n",
      "\tinput #1 has shape [ 1 64 55 55]\n",
      "\toutput #0 has shape [  1 128  55  55]\n",
      "  Layer fire4/squeeze1x1 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [  1 128  55  55]\n",
      "\toutput #0 has shape [  1 128  27  27]\n",
      "  Layer fire4/relu_squeeze1x1 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [  1 128  27  27]\n",
      "\toutput #0 has shape [ 1 32 27 27]\n",
      "  Layer fire4/expand1x1 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [ 1 32 27 27]\n",
      "\toutput #0 has shape [ 1 32 27 27]\n",
      "  Layer fire4/relu_expand1x1 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [ 1 32 27 27]\n",
      "\toutput #0 has shape [  1 128  27  27]\n",
      "  Layer fire4/expand3x3 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [  1 128  27  27]\n",
      "\toutput #0 has shape [  1 128  27  27]\n",
      "  Layer fire4/relu_expand3x3 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [ 1 32 27 27]\n",
      "\toutput #0 has shape [  1 128  27  27]\n",
      "  Layer fire4/concat has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [  1 128  27  27]\n",
      "\toutput #0 has shape [  1 128  27  27]\n",
      "  Layer fire5/squeeze1x1 has 2 inputs and 1 outputs\n",
      "\tinput #0 has shape [  1 128  27  27]\n",
      "\tinput #1 has shape [  1 128  27  27]\n",
      "\toutput #0 has shape [  1 256  27  27]\n",
      "  Layer fire5/relu_squeeze1x1 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [  1 256  27  27]\n",
      "\toutput #0 has shape [ 1 32 27 27]\n",
      "  Layer fire5/expand1x1 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [ 1 32 27 27]\n",
      "\toutput #0 has shape [ 1 32 27 27]\n",
      "  Layer fire5/relu_expand1x1 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [ 1 32 27 27]\n",
      "\toutput #0 has shape [  1 128  27  27]\n",
      "  Layer fire5/expand3x3 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [  1 128  27  27]\n",
      "\toutput #0 has shape [  1 128  27  27]\n",
      "  Layer fire5/relu_expand3x3 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [ 1 32 27 27]\n",
      "\toutput #0 has shape [  1 128  27  27]\n",
      "  Layer fire5/concat has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [  1 128  27  27]\n",
      "\toutput #0 has shape [  1 128  27  27]\n",
      "  Layer pool5 has 2 inputs and 1 outputs\n",
      "\tinput #0 has shape [  1 128  27  27]\n",
      "\tinput #1 has shape [  1 128  27  27]\n",
      "\toutput #0 has shape [  1 256  27  27]\n",
      "  Layer fire6/squeeze1x1 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [  1 256  27  27]\n",
      "\toutput #0 has shape [  1 256  13  13]\n",
      "  Layer fire6/relu_squeeze1x1 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [  1 256  13  13]\n",
      "\toutput #0 has shape [ 1 48 13 13]\n",
      "  Layer fire6/expand1x1 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [ 1 48 13 13]\n",
      "\toutput #0 has shape [ 1 48 13 13]\n",
      "  Layer fire6/relu_expand1x1 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [ 1 48 13 13]\n",
      "\toutput #0 has shape [  1 192  13  13]\n",
      "  Layer fire6/expand3x3 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [  1 192  13  13]\n",
      "\toutput #0 has shape [  1 192  13  13]\n",
      "  Layer fire6/relu_expand3x3 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [ 1 48 13 13]\n",
      "\toutput #0 has shape [  1 192  13  13]\n",
      "  Layer fire6/concat has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [  1 192  13  13]\n",
      "\toutput #0 has shape [  1 192  13  13]\n",
      "  Layer fire7/squeeze1x1 has 2 inputs and 1 outputs\n",
      "\tinput #0 has shape [  1 192  13  13]\n",
      "\tinput #1 has shape [  1 192  13  13]\n",
      "\toutput #0 has shape [  1 384  13  13]\n",
      "  Layer fire7/relu_squeeze1x1 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [  1 384  13  13]\n",
      "\toutput #0 has shape [ 1 48 13 13]\n",
      "  Layer fire7/expand1x1 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [ 1 48 13 13]\n",
      "\toutput #0 has shape [ 1 48 13 13]\n",
      "  Layer fire7/relu_expand1x1 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [ 1 48 13 13]\n",
      "\toutput #0 has shape [  1 192  13  13]\n",
      "  Layer fire7/expand3x3 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [  1 192  13  13]\n",
      "\toutput #0 has shape [  1 192  13  13]\n",
      "  Layer fire7/relu_expand3x3 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [ 1 48 13 13]\n",
      "\toutput #0 has shape [  1 192  13  13]\n",
      "  Layer fire7/concat has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [  1 192  13  13]\n",
      "\toutput #0 has shape [  1 192  13  13]\n",
      "  Layer fire8/squeeze1x1 has 2 inputs and 1 outputs\n",
      "\tinput #0 has shape [  1 192  13  13]\n",
      "\tinput #1 has shape [  1 192  13  13]\n",
      "\toutput #0 has shape [  1 384  13  13]\n",
      "  Layer fire8/relu_squeeze1x1 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [  1 384  13  13]\n",
      "\toutput #0 has shape [ 1 64 13 13]\n",
      "  Layer fire8/expand1x1 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [ 1 64 13 13]\n",
      "\toutput #0 has shape [ 1 64 13 13]\n",
      "  Layer fire8/relu_expand1x1 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [ 1 64 13 13]\n",
      "\toutput #0 has shape [  1 256  13  13]\n",
      "  Layer fire8/expand3x3 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [  1 256  13  13]\n",
      "\toutput #0 has shape [  1 256  13  13]\n",
      "  Layer fire8/relu_expand3x3 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [ 1 64 13 13]\n",
      "\toutput #0 has shape [  1 256  13  13]\n",
      "  Layer fire8/concat has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [  1 256  13  13]\n",
      "\toutput #0 has shape [  1 256  13  13]\n",
      "  Layer fire9/squeeze1x1 has 2 inputs and 1 outputs\n",
      "\tinput #0 has shape [  1 256  13  13]\n",
      "\tinput #1 has shape [  1 256  13  13]\n",
      "\toutput #0 has shape [  1 512  13  13]\n",
      "  Layer fire9/relu_squeeze1x1 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [  1 512  13  13]\n",
      "\toutput #0 has shape [ 1 64 13 13]\n",
      "  Layer fire9/expand1x1 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [ 1 64 13 13]\n",
      "\toutput #0 has shape [ 1 64 13 13]\n",
      "  Layer fire9/relu_expand1x1 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [ 1 64 13 13]\n",
      "\toutput #0 has shape [  1 256  13  13]\n",
      "  Layer fire9/expand3x3 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [  1 256  13  13]\n",
      "\toutput #0 has shape [  1 256  13  13]\n",
      "  Layer fire9/relu_expand3x3 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [ 1 64 13 13]\n",
      "\toutput #0 has shape [  1 256  13  13]\n",
      "  Layer fire9/concat has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [  1 256  13  13]\n",
      "\toutput #0 has shape [  1 256  13  13]\n",
      "  Layer drop9 has 2 inputs and 1 outputs\n",
      "\tinput #0 has shape [  1 256  13  13]\n",
      "\tinput #1 has shape [  1 256  13  13]\n",
      "\toutput #0 has shape [  1 512  13  13]\n",
      "  Layer conv10 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [  1 512  13  13]\n",
      "\toutput #0 has shape [  1 512  13  13]\n",
      "  Layer relu_conv10 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [  1 512  13  13]\n",
      "\toutput #0 has shape [   1 1000   13   13]\n",
      "  Layer pool10 has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [   1 1000   13   13]\n",
      "\toutput #0 has shape [   1 1000   13   13]\n",
      "  Layer pool10_flatten has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [   1 1000   13   13]\n",
      "\toutput #0 has shape [   1 1000    1    1]\n",
      "  Layer prob has 1 inputs and 1 outputs\n",
      "\tinput #0 has shape [   1 1000    1    1]\n",
      "\toutput #0 has shape [   1 1000]\n"
     ]
    }
   ],
   "source": [
    "squeezenet_summary(squeezenet, layer_shape=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gflops:  0.7066281600000001\n",
      "\n",
      "weights (mb): 4.941984 , blobs (mb): 28.797728\n"
     ]
    }
   ],
   "source": [
    "squeezenet_summary(squeezenet, get_flops=True, get_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "inference (ms): 228.607952\n",
      "\n",
      "LAYER                          TIME (ms)\n",
      "conv1                          8.18\n",
      "relu_conv1                     0.00\n",
      "pool1                          3.11\n",
      "fire2/squeeze1x1               1.94\n",
      "fire2/relu_squeeze1x1          0.00\n",
      "fire2/expand1x1                9.84\n",
      "fire2/relu_expand1x1           0.00\n",
      "fire2/expand3x3                16.31\n",
      "fire2/relu_expand3x3           0.00\n",
      "fire2/concat                   0.00\n",
      "fire3/squeeze1x1               3.22\n",
      "fire3/relu_squeeze1x1          0.00\n",
      "fire3/expand1x1                41.52\n",
      "fire3/relu_expand1x1           0.00\n",
      "fire3/expand3x3                30.71\n",
      "fire3/relu_expand3x3           0.00\n",
      "fire3/concat                   0.00\n",
      "pool3                          2.18\n",
      "fire4/squeeze1x1               1.35\n",
      "fire4/relu_squeeze1x1          0.00\n",
      "fire4/expand1x1                1.72\n",
      "fire4/relu_expand1x1           0.00\n",
      "fire4/expand3x3                8.36\n",
      "fire4/relu_expand3x3           0.00\n",
      "fire4/concat                   0.00\n",
      "fire5/squeeze1x1               0.92\n",
      "fire5/relu_squeeze1x1          0.00\n",
      "fire5/expand1x1                1.93\n",
      "fire5/relu_expand1x1           0.00\n",
      "fire5/expand3x3                6.10\n",
      "fire5/relu_expand3x3           0.00\n",
      "fire5/concat                   0.00\n",
      "pool5                          1.28\n",
      "fire6/squeeze1x1               0.44\n",
      "fire6/relu_squeeze1x1          0.00\n",
      "fire6/expand1x1                0.30\n",
      "fire6/relu_expand1x1           0.00\n",
      "fire6/expand3x3                3.23\n",
      "fire6/relu_expand3x3           0.00\n",
      "fire6/concat                   0.00\n",
      "fire7/squeeze1x1               0.96\n",
      "fire7/relu_squeeze1x1          0.00\n",
      "fire7/expand1x1                0.34\n",
      "fire7/relu_expand1x1           0.00\n",
      "fire7/expand3x3                2.17\n",
      "fire7/relu_expand3x3           0.00\n",
      "fire7/concat                   0.00\n",
      "fire8/squeeze1x1               0.82\n",
      "fire8/relu_squeeze1x1          0.00\n",
      "fire8/expand1x1                0.75\n",
      "fire8/relu_expand1x1           0.00\n",
      "fire8/expand3x3                8.25\n",
      "fire8/relu_expand3x3           0.00\n",
      "fire8/concat                   0.00\n",
      "fire9/squeeze1x1               3.29\n",
      "fire9/relu_squeeze1x1          0.00\n",
      "fire9/expand1x1                0.88\n",
      "fire9/relu_expand1x1           0.00\n",
      "fire9/expand3x3                6.08\n",
      "fire9/relu_expand3x3           0.00\n",
      "fire9/concat                   0.00\n",
      "drop9                          0.09\n",
      "conv10                         61.96\n",
      "relu_conv10                    0.00\n",
      "pool10                         0.33\n",
      "pool10_flatten                 0.01\n",
      "prob                           0.05\n"
     ]
    }
   ],
   "source": [
    "squeezenet_summary(squeezenet, get_total_time=True, get_layer_time=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
